# Container Diagram Implementation: AI Dermatology Expert Chat System

## ğŸ“‹ Overview
This document details the **real code implementation** of the Container Diagram (Level 2 C4 Model) for the AI Dermatology Expert chat system, showing how user queries are embedded, compared with vector database embeddings, and processed through the RAG pipeline.

---

## ğŸ—ï¸ Container Architecture Components

### 1. **Frontend Container** (Web/Mobile)
- **Technology**: Vue.js 3 (Web), React Native (Mobile)
- **Responsibility**: User interface for chat interactions
- **Files**: 
  - `frontend/src/pages/customer/skin-study/AIDermatologyExpert.vue`
  - `mobile-app-customer/src/components/skinStudy/AIDermatologyExpert.js`

### 2. **API Gateway Container** (Express.js Backend)
- **Technology**: Node.js + Express.js
- **Port**: 3000 (default)
- **Responsibility**: Route requests, handle authentication, manage file uploads
- **Key Files**:
  - `backend/routes/skin-study/aiDermatologyExpert.js`
  - `backend/controllers/skin-study/aiDermatologyExpertController.js`

### 3. **Vector Database Container** (Qdrant)
- **Technology**: Qdrant Vector Database
- **Default URL**: `http://localhost:6333`
- **Collection**: `dermatology_knowledge`
- **Vector Dimension**: 768 (Gemini embeddings)
- **Distance Metric**: Cosine Similarity
- **Responsibility**: Store and retrieve dermatology knowledge embeddings

### 4. **Embedding Service** (Google Gemini)
- **Model**: `text-embedding-004`
- **Dimension**: 768
- **Responsibility**: Generate embeddings for user queries and documents
- **Used by**: `vectorService.js`

### 5. **LLM Service** (Google Gemini API)
- **Model**: `gemini-2.0-flash`
- **Responsibility**: Generate responses using RAG context
- **Used by**: `geminiService.js`

### 6. **Database Container** (MongoDB)
- **Technology**: MongoDB Atlas
- **Responsibility**: Store conversation history, user data, cache
- **Collections**: 
  - `conversations` - Chat history
  - `ai_dermatology_cache` - Cached responses

### 7. **Knowledge Base Container** (Text Files)
- **Location**: `backend/knowledge-sources/extracted-content/`
- **Format**: `.txt` files from dermatology textbooks
- **Content**: 6 dermatology textbooks with ~1500 chunks each

---

## ğŸ”„ Data Flow: User Query to AI Response

### **Step 1: User Sends Query**
```
Frontend (Vue.js/React Native)
    â†“
    POST /api/ai-dermatology-expert/chat
    {
        "message": "I have red patches on my cheeks",
        "conversationHistory": [...]
    }
```

**Code Location**: `backend/routes/skin-study/aiDermatologyExpert.js`
```javascript
router.post('/chat', aiDermatologyExpertController.chat);
```

---

### **Step 2: Controller Receives Request**
**File**: `backend/controllers/skin-study/aiDermatologyExpertController.js`

```javascript
exports.chat = async (req, res) => {
    const { message, conversationHistory } = req.body;
    
    // Step 2.1: Detect and translate query if needed
    const translationResult = await geminiService.detectAndTranslate(message);
    const queryForRAG = translationResult.translatedText; // English for vector search
    
    // Step 2.2: Check cache for sample questions
    const isSampleQuestion = cacheService.isSampleQuestion(message);
    let cachedResponse = null;
    if (isSampleQuestion || !conversationHistory || conversationHistory.length === 0) {
        cachedResponse = await cacheService.getAIDermatologyResponse(message, translationResult.languageName);
    }
    
    if (cachedResponse) {
        return res.json(cachedResponse); // Return cached response
    }
    
    // Step 2.3: No cache hit - proceed to RAG
    const ragResult = await vectorService.ragQuery(queryForRAG, conversationHistory);
    
    // Step 2.4: Generate response with context
    const result = await geminiService.generateResponseWithContext(
        message,
        ragResult.context,
        conversationHistory
    );
    
    res.json({
        response: result.response,
        sources: ragResult.sources,
        timestamp: new Date()
    });
};
```

---

### **Step 3: Language Detection & Translation**
**File**: `backend/services/geminiService.js`

```javascript
async detectAndTranslate(text) {
    // Uses Gemini to detect language and translate to English
    const prompt = `Analyze this text and respond ONLY with a JSON object:
{
  "language": "<language code>",
  "languageName": "<language name>",
  "translation": "<English translation>"
}`;
    
    const result = await this.translationModel.generateContent(prompt);
    return {
        isEnglish: parsed.language === 'en',
        originalText: text,
        translatedText: parsed.translation,
        detectedLanguage: parsed.language,
        languageName: parsed.languageName
    };
}
```

**Why?** English queries get better vector search results from the English knowledge base.

---

### **Step 4: Query Embedding & Vector Search (RAG)**
**File**: `backend/services/vectorService.js`

#### **4.1: Initialize Vector Service**
```javascript
async initialize() {
    // Initialize Qdrant client
    this.qdrantClient = new QdrantClient({
        url: 'http://localhost:6333',
        apiKey: process.env.QDRANT_API_KEY
    });
    
    // Initialize Gemini embeddings
    this.embeddings = new GoogleGenerativeAIEmbeddings({
        apiKey: process.env.GEMINI_API_KEY,
        modelName: 'text-embedding-004' // 768-dimensional vectors
    });
}
```

#### **4.2: Embed User Query**
```javascript
async ragQuery(userQuery, conversationHistory = []) {
    // Generate embedding for user query
    const queryEmbedding = await this.embeddings.embedQuery(userQuery);
    
    console.log('Query Vector Length:', queryEmbedding.length); // 768
    console.log('Query Vector Sample:', queryEmbedding.slice(0, 5));
    // Output: [0.1234, -0.5678, 0.9012, ...]
}
```

**What happens:**
- User query: `"I have red patches on my cheeks"`
- Converted to 768-dimensional vector using Gemini's `text-embedding-004` model
- Example vector: `[0.123, -0.456, 0.789, ..., 0.234]` (768 values)

#### **4.3: Search Vector Database**
```javascript
// Search in Qdrant with cosine similarity
const searchResults = await this.qdrantClient.search(this.collectionName, {
    vector: queryEmbedding,        // 768-dim query vector
    limit: 3,                       // Top 3 most similar chunks
    with_payload: true,
    score_threshold: 0.4            // Only return >40% similarity
});
```

**Cosine Similarity Calculation:**
```
similarity = (A Â· B) / (||A|| Ã— ||B||)

Where:
- A = Query embedding vector (768 dimensions)
- B = Document chunk embedding vector (768 dimensions)
- Result: 0.0 (completely different) to 1.0 (identical meaning)
```

#### **4.4: Retrieve Relevant Chunks**
```javascript
console.log('ğŸ“š Retrieved 3 chunks from Qdrant:\n');

// Chunk 1: Score 0.8234 (82.34% similarity) âœ… EXCELLENT
// Source: "Fitzpatrick's Dermatology in General Medicine"
// Text: "Rosacea is a chronic inflammatory skin condition characterized by..."

// Chunk 2: Score 0.7156 (71.56% similarity) âœ… GOOD
// Source: "Textbook of Cosmetic Dermatology"
// Text: "Contact dermatitis presents as localized erythema..."

// Chunk 3: Score 0.6234 (62.34% similarity) âœ… FAIR
// Source: "Cosmetic Dermatology - Principles and Practice"
// Text: "Inflammatory skin conditions require proper diagnosis..."

// Score Statistics:
// Highest: 0.8234 (100% match)
// Average: 0.7208 (72.08% avg similarity)
// Lowest:  0.6234 (62.34% similarity)
```

**Scoring Explained:**
- **0.90+**: Perfect match - directly answers the question
- **0.75-0.89**: Excellent - highly relevant
- **0.60-0.74**: Good - relevant information
- **0.45-0.59**: Fair - tangentially related
- **<0.45**: Filtered out (below threshold)

---

### **Step 5: Build RAG Context**
```javascript
// Combine all retrieved chunks into a single context string
const context = relevantDocs
    .map((doc, idx) => {
        const bookTitle = doc.metadata.source;
        return `[Source ${idx + 1} - "${bookTitle}"]\n${doc.content}`;
    })
    .join('\n\n---\n\n');

// Result:
/*
[Source 1 - "Fitzpatrick's Dermatology in General Medicine"]
Rosacea is a chronic inflammatory skin condition characterized by facial erythema, 
telangiectasia, papules, and pustules...

---

[Source 2 - "Textbook of Cosmetic Dermatology"]
Contact dermatitis presents as localized erythema, pruritus, and inflammation 
following exposure to allergens or irritants...

---

[Source 3 - "Cosmetic Dermatology - Principles and Practice"]
Inflammatory skin conditions require proper diagnosis through clinical examination 
and sometimes patch testing...
*/
```

---

### **Step 6: Generate Response with Gemini LLM**
**File**: `backend/services/geminiService.js`

```javascript
async generateResponseWithContext(userMessage, ragContext, conversationHistory) {
    // Build comprehensive prompt
    let fullPrompt = `You are a Virtual Dermatology Expert...

=== RELEVANT KNOWLEDGE FROM DERMATOLOGY TEXTBOOK ===
${ragContext}
=== END OF KNOWLEDGE BASE ===

CRITICAL INSTRUCTIONS:
1. Use ALL information from the knowledge base above
2. Synthesize information from multiple sources
3. Cite your sources inline using [1], [2], [3] format
4. Structure responses with headers and bullet points

CITATION REQUIREMENT:
- Use bracketed numbers [1], [2], [3] to reference source chunks
- Place citations at end of sentences
- Example: "Rosacea is characterized by facial erythema.[1]"
- At END of response, add "### References" section with unique book titles

Previous conversation:
${conversationHistory.map(msg => `${msg.role}: ${msg.content}`).join('\n')}

Patient: ${userMessage}
Dermatology Expert:`;

    // Call Gemini with retry logic
    const result = await this.generateWithRetry(fullPrompt);
    const response = await result.response;
    
    return {
        response: response.text(),
        method: 'rag-vector-search'
    };
}
```

**Gemini Model Configuration:**
```javascript
this.model = this.genAI.getGenerativeModel({ 
    model: 'gemini-2.0-flash',
    generationConfig: {
        temperature: 0.7,           // Balanced creativity
        topP: 0.9,
        topK: 40,
        maxOutputTokens: 4096       // Detailed responses
    }
});
```

---

### **Step 7: Return Response to Frontend**
```javascript
res.json({
    response: "Based on the image analysis, I can observe red patches on both cheeks...",
    sources: [
        {
            text: "Rosacea is a chronic inflammatory skin condition...",
            score: 0.8234,
            metadata: {
                source: "Fitzpatrick's Dermatology in General Medicine",
                chunkIndex: 45
            }
        },
        // ... more sources
    ],
    timestamp: "2024-11-30T11:05:42.567Z",
    _performance: {
        totalTime: 4523,
        contextSize: 4187,
        chunks: 3
    }
});
```

---

## ğŸ“Š Embedding Comparison Process

### **Vector Database Structure**
```
Qdrant Collection: "dermatology_knowledge"
â”œâ”€â”€ Vector Size: 768 dimensions
â”œâ”€â”€ Distance Metric: Cosine Similarity
â”œâ”€â”€ Total Points: ~9,000 chunks
â””â”€â”€ Points Structure:
    {
        id: 1,
        vector: [0.123, -0.456, ..., 0.789],  // 768 values
        payload: {
            text: "Rosacea is a chronic inflammatory...",
            metadata: {
                source: "Fitzpatrick's Dermatology",
                chunkIndex: 45,
                fileChunkIndex: 12
            }
        }
    }
```

### **Query Embedding Process**
```
User Query: "I have red patches on my cheeks"
    â†“
Gemini text-embedding-004 Model
    â†“
768-Dimensional Vector: [0.234, -0.567, 0.891, ..., 0.345]
    â†“
Qdrant Vector Search (Cosine Similarity)
    â†“
Top 3 Most Similar Chunks:
    1. Score: 0.8234 âœ… (Rosacea - highly relevant)
    2. Score: 0.7156 âœ… (Contact Dermatitis - relevant)
    3. Score: 0.6234 âœ… (General Inflammation - somewhat relevant)
```

### **Cosine Similarity Calculation Example**
```
Query Vector:     [0.234, -0.567, 0.891, ..., 0.345]
Chunk 1 Vector:   [0.245, -0.580, 0.905, ..., 0.358]

Dot Product (A Â· B):
= 0.234Ã—0.245 + (-0.567)Ã—(-0.580) + 0.891Ã—0.905 + ... + 0.345Ã—0.358
= 0.0573 + 0.3289 + 0.8063 + ... + 0.1235
= 612.45 (sum of all 768 multiplications)

Magnitude ||A||: âˆš(0.234Â² + 0.567Â² + 0.891Â² + ... + 0.345Â²) = 28.34
Magnitude ||B||: âˆš(0.245Â² + 0.580Â² + 0.905Â² + ... + 0.358Â²) = 28.67

Cosine Similarity = 612.45 / (28.34 Ã— 28.67) = 0.8234 (82.34%)
```

---

## [object Object] Endpoints in Container Diagram

### **1. Chat Endpoint**
```
POST /api/ai-dermatology-expert/chat
Content-Type: application/json

Request:
{
    "message": "I have red patches on my cheeks",
    "conversationHistory": [
        {"role": "user", "content": "What is rosacea?"},
        {"role": "assistant", "content": "Rosacea is..."}
    ]
}

Response:
{
    "response": "Based on your description...",
    "sources": [
        {
            "text": "Rosacea is a chronic inflammatory...",
            "score": 0.8234,
            "metadata": {...}
        }
    ],
    "timestamp": "2024-11-30T11:05:42.567Z"
}
```

### **2. Analyze Skin Image Endpoint**
```
POST /api/ai-dermatology-expert/analyze-skin
Content-Type: multipart/form-data

Request:
- image: [binary file - skin-condition.jpg]
- message: "I've been experiencing these red patches"
- conversationHistory: "[]"

Process:
1. Upload image to backend
2. Generate embedding for user message
3. Query vector DB for relevant dermatology knowledge
4. Send image + context to Gemini Vision API
5. Return analysis with sources

Response:
{
    "response": "Based on the image analysis, I observe...",
    "sources": [...],
    "timestamp": "2024-11-30T11:05:42.567Z"
}
```

### **3. Transcribe Audio Endpoint**
```
POST /api/ai-dermatology-expert/transcribe
Content-Type: multipart/form-data

Request:
- audio: [binary file - voice-query.m4a]

Process:
1. Upload audio file
2. Send to Gemini for transcription
3. Return transcribed text

Response:
{
    "transcription": "I have red patches on my cheeks",
    "timestamp": "2024-11-30T11:05:42.567Z",
    "processingTime": 2345
}
```

### **4. Text-to-Speech Endpoint**
```
POST /api/ai-dermatology-expert/text-to-speech
Content-Type: application/json

Request:
{
    "text": "Based on your description, you may have rosacea..."
}

Response:
{
    "audio": "SUQzBAAAI1IVVFJJVDIwMjQxMTMwVDExMDU0Mg==...",
    "format": "mp3",
    "timestamp": "2024-11-30T11:05:42.567Z",
    "processingTime": 1234
}
```

---

## ğŸ”Œ Container Interactions

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        FRONTEND CONTAINER                        â”‚
â”‚  (Vue.js Web / React Native Mobile)                             â”‚
â”‚  - User input (text/voice/image)                                â”‚
â”‚  - Display AI response + sources                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚ HTTP/REST
                     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   API GATEWAY CONTAINER                          â”‚
â”‚  (Express.js Backend - Port 3000)                               â”‚
â”‚  - Route requests                                               â”‚
â”‚  - File upload handling (multer)                                â”‚
â”‚  - JWT authentication                                           â”‚
â”‚  - Controller logic                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                  â”‚                  â”‚
         â†“                  â†“                  â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   VECTOR    â”‚  â”‚   GEMINI     â”‚  â”‚   MONGODB    â”‚
    â”‚  DATABASE   â”‚  â”‚     API      â”‚  â”‚   DATABASE   â”‚
    â”‚  (Qdrant)   â”‚  â”‚  (LLM/Vision)â”‚  â”‚   (Atlas)    â”‚
    â”‚             â”‚  â”‚              â”‚  â”‚              â”‚
    â”‚ 768-dim     â”‚  â”‚ - Chat       â”‚  â”‚ - Chats      â”‚
    â”‚ vectors     â”‚  â”‚ - Vision     â”‚  â”‚ - Cache      â”‚
    â”‚ ~9,000      â”‚  â”‚ - Embedding  â”‚  â”‚ - Users      â”‚
    â”‚ chunks      â”‚  â”‚ - TTS        â”‚  â”‚              â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†‘                  â†‘
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         Embedding Service
         (text-embedding-004)

    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  KNOWLEDGE BASE CONTAINER    â”‚
    â”‚  (Text Files)                â”‚
    â”‚  - 6 dermatology textbooks   â”‚
    â”‚  - ~9,000 chunks             â”‚
    â”‚  - Indexed into Qdrant       â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ˆ Performance Metrics

### **Typical Response Time Breakdown**
```
Total Time: ~4,500 ms

1. Language Detection:        ~800 ms (Gemini API call)
2. Query Embedding:           ~400 ms (Generate 768-dim vector)
3. Vector Search:             ~100 ms (Qdrant similarity search)
4. Context Building:          ~50 ms  (String concatenation)
5. Response Generation:       ~2,500 ms (Gemini LLM generation)
6. Response Formatting:       ~50 ms  (JSON serialization)
7. Database Save:             ~600 ms (MongoDB write)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Total:                        ~4,500 ms
```

### **Cache Performance**
```
Without Cache:  ~4,500 ms (full RAG pipeline)
With Cache:     ~100 ms   (direct retrieval from MongoDB)
Improvement:    ~45x faster for cached queries
```

---

## ğŸ” Security Features

### **1. Input Validation**
- Message length validation
- File type validation (images, audio)
- File size limits (10MB)

### **2. Authentication**
- JWT token validation
- User context from token

### **3. Rate Limiting**
- Gemini API retry logic (exponential backoff)
- Qdrant connection pooling

### **4. Error Handling**
- Graceful degradation on API failures
- User-friendly error messages
- Development mode detailed errors

---

## ğŸš€ Deployment Architecture

### **Development**
```
localhost:3000 (Backend)
â”œâ”€â”€ Express.js API
â”œâ”€â”€ Qdrant (localhost:6333)
â””â”€â”€ MongoDB (local or Atlas)
```

### **Production**
```
Docker Containers:
â”œâ”€â”€ Backend Service (Node.js)
â”œâ”€â”€ Qdrant Vector DB
â””â”€â”€ MongoDB Atlas (managed)

Environment Variables:
- GEMINI_API_KEY
- QDRANT_URL
- QDRANT_API_KEY
- MONGODB_URI
- NODE_ENV=production
```

---

## ğŸ“š Knowledge Base Integration

### **Loading Process**
```
1. Read all .txt files from knowledge-sources/extracted-content/
   - Fitzpatrick's Dermatology in General Medicine
   - Textbook of Cosmetic Dermatology
   - Chemical Peels - Procedures in Cosmetic Dermatology
   - Lasers in Dermatology and Medicine
   - Cosmetic Dermatology - Products and Procedures
   - Cosmetic Dermatology - Principles and Practice

2. Split each file into chunks
   - Chunk size: 1,500 characters
   - Overlap: 300 characters (for context continuity)
   - Total chunks: ~9,000

3. Generate embeddings for each chunk
   - Model: text-embedding-004
   - Dimension: 768
   - Batch size: 50 chunks

4. Index into Qdrant
   - Collection: dermatology_knowledge
   - Distance: Cosine Similarity
   - Ready for vector search
```

---

## ğŸ“ Summary: Container Diagram Flow

```
USER QUERY
    â†“
[Frontend] Sends message
    â†“
[API Gateway] Receives request
    â†“
[Gemini] Detects language & translates to English
    â†“
[Cache] Checks if response is cached
    â†“ (if not cached)
[Gemini] Generates 768-dim embedding for query
    â†“
[Qdrant] Searches for 3 most similar chunks
    â†“ (using Cosine Similarity)
[Qdrant] Returns top 3 chunks with scores
    â†“
[Backend] Builds RAG context from chunks
    â†“
[Gemini] Generates response using context
    â†“
[MongoDB] Saves conversation
    â†“
[Frontend] Displays response + sources
```

---

## ğŸ“ Key Files Reference

| File | Purpose |
|------|---------|
| `backend/controllers/skin-study/aiDermatologyExpertController.js` | Main controller logic |
| `backend/services/vectorService.js` | Vector DB & RAG pipeline |
| `backend/services/geminiService.js` | Gemini API integration |
| `backend/routes/skin-study/aiDermatologyExpert.js` | API routes |
| `backend/services/cacheService.js` | Response caching |
| `backend/knowledge-sources/extracted-content/` | Knowledge base files |

---

This document provides a complete technical breakdown of the Container Diagram implementation for the AI Dermatology Expert chat system, showing exactly how embeddings, vector searches, and RAG work in the real codebase.

